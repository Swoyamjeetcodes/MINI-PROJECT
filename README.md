# ML-Based Compiler Optimization Prediction ğŸš€ğŸ–¥ï¸ğŸ“Š

## Overview âœ¨ğŸ”ğŸ“‰

This project explores optimizing C code compilation using machine learning. The goal is to predict the best compiler optimization flag for minimizing execution time. The workflow involves generating 10,000 C programs, extracting relevant features, and training a model using a Random Forest algorithm. ğŸ¯ğŸ¤–ğŸ“ˆ

## Project Structure ğŸ“ğŸ“ŒğŸ“‚

```
.
â”œâ”€â”€ .ipynb_checkpoints/        # Jupyter Notebook checkpoints
â”œâ”€â”€ data/                      # Directory for dataset CSV files
â”œâ”€â”€ example_c_files_for_model/ # Example C programs used for training
â”œâ”€â”€ LICENSE                    # License information
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ datasetgenerator.py        # Script to generate random C programs
â”œâ”€â”€ featureextraction.py       # Script to extract features from C programs
â”œâ”€â”€ features.csv               # Extracted feature dataset
â”œâ”€â”€ model.ipynb                # Jupyter Notebook for training the ML model
â”œâ”€â”€ random_forest_no_pkl.ipynb # Model training without using pickle files
```

## Steps ğŸ› ï¸ğŸ”¢ğŸ“‹

### 1. Generating the Dataset ğŸ²ğŸ“œğŸ’¾

- `datasetgenerator.py` generates 10,000 C programs with varying structures.
- The generated C files are stored in `example_c_files_for_model/`.

### 2. Extracting Features ğŸ“ŠğŸ”ğŸ“‘

- `featureextraction.py` processes each C file to extract static, dynamic, and compiler-specific features.
- Extracted features are stored in `features.csv`.

### 3. Training the Model ğŸ‹ï¸â€â™‚ï¸ğŸ¤–ğŸ›ï¸

- `model.ipynb` trains a machine learning model (Random Forest) to predict the best compiler optimization flag for execution time.
- `random_forest_no_pkl.ipynb` provides an alternative approach without serialization.

## Features Extracted ğŸ“ŒğŸ“ŠğŸ› ï¸

âœ… **Static Features** (Code Structure)

- Lines of Code (LOC)
- Number of Functions, Loops, Conditionals
- Number of Variables, Function Calls
- Number of Recursive Calls

âœ… **Dynamic Features** (Runtime Performance)

- Compilation Time
- Execution Time

âœ… **Compiler-Specific Features**

- Different Optimization Flags (-O0 to -Ofast)
- Performance impact of each flag

## Results ğŸ¯âš¡ğŸ“‰

- The trained model predicts the best optimization flag for new C programs.
- Improves execution time by selecting the most efficient flag based on extracted features.

## Usage ğŸš€ğŸ“œğŸ–¥ï¸

1. Run `datasetgenerator.py` to generate C files.
2. Execute `featureextraction.py` to extract features.
3. Open `model.ipynb` to train and evaluate the model.

## License ğŸ“œâš–ï¸ğŸ”“

This project is licensed under the [MIT License](LICENSE).

